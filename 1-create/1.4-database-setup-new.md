# Day 1: Create

[⬅️ Day 1 Overview](README.md)

## 1.4 Database Setup Introduction

**Goal**: Define the data structure (schema) required for the web application, creating a set of migration files that will fully install a custom Postgres database into your Supabase instance. Also create a `seed.sql` file to populate an initial dataset.

**Process**: Follow this chat pattern with an AI chat tool such as [Claude.ai](https://www.claude.ai). Pay attention to the notes in `[brackets]` and replace the brackets with your own thoughts and ideas.

**Timeframe**: 30-45 minutes

## Table of Contents
- [1.4.1: Initial Schema Analysis](#141-initial-schema-analysis)
- [1.4.2: Foundation Migration](#142-foundation-migration)
- [1.4.3: Structure Migration](#143-structure-migration)
- [1.4.4: Relationships Migration](#144-relationships-migration)
- [1.4.5: Security Migration](#145-security-migration)
- [1.4.6: Seed Data](#146-seed-data)
- [1.4.7: Schema Validation](#147-schema-validation)
- [1.4.8: Installation Instructions](#148-installation-instructions)

## 1.4 Database Setup Generation

### 1.4.1: Initial Schema Analysis

```
You are a Supabase and Postgres and SQL expert tasked with helping an entrepreneur turn product requirements into a well-structured Supabase database. You'll help analyze requirements and create properly organized migration files.

Supabase has reserved schemas with special purposes:
- `auth` - Authentication and user management
- `storage` - File storage and management
- `graphql` - GraphQL API
- `realtime` - Realtime subscriptions
- `supabase_functions` - Edge functions

Custom schemas should be organized as:
- `api` - User-generated content and application data
- `config` - Application configuration data
- `reference` - Publicly available lookup tables
- `analytics` - Reporting data (primarily views)
- `stripe` - Synced data from Stripe webhooks (if using Stripe)

Please paste your completed `product-requirements.md` document from step 1.1:

<product-requirements>
[Paste your PRD here]
</product-requirements>

Based on these requirements, please analyze the core entities needed for your database schema:

1. The schema organization:
   - What custom schemas should we create?
   - What types of data should go in each schema?
   - What enums should we place in the reference schema?

2. Core business objects specific to your application:
   - What are the main entities that represent your application's unique value?
   - How do these entities relate to users?
   - What timestamps and audit fields should be included?

3. Profile and authentication extensions:
   - How should we extend the default auth.users table?
   - What additional user-related data do we need to store?
   - How should we handle user roles and permissions?

4. Subscription and billing tables (if applicable):
   - Do we need to implement Stripe integration tables?
   - What customizations do we need for your pricing model?

5. Usage tracking and analytics requirements:
   - What usage metrics do we need to track?
   - How will this data be structured for reporting?

For each entity, please identify:
- Key attributes/columns
- Primary identifiers (UUIDs vs serial IDs)
- Basic relationships to other entities
- Access patterns (who needs to read/write this data)

Don't write SQL yet - just create an initial analysis of entities, relationships, and key security/access patterns.
```

### 1.4.2: Foundation Migration

```
Thank you for the initial analysis. Now let's create our first migration file: `000-foundation.sql` which will establish the foundation of our database structure.

When creating database schemas, follow these best practices:
- Use UUIDs as primary keys for better distribution and security
- Include created_at and updated_at timestamps on all tables
- Use foreign key constraints to maintain referential integrity
- Consider soft deletes with a deleted_at timestamp instead of hard deletes

In this migration, we'll include:

1. EXTENSIONS
   - Enable all required PostgreSQL extensions (pgcrypto, pg_graphql, etc.)

2. SCHEMAS
   - Create all custom schemas needed for our application
   - Document the purpose of each schema

3. TYPES AND DOMAINS
   - Define all enums and custom types
   - Create domain types if needed (email, url, etc.)
   - Place enums in the reference schema

Please generate the complete 000-foundation.sql file based on our application requirements.
```

### 1.4.3: Structure Migration

```
Great! Now let's create our second migration file: `001-structure.sql` which will define the core data structures of our application.

This migration will include:

1. UTILITY FUNCTIONS
   - Create reusable utility functions that will be used by triggers and policies
   - Follow security best practices for function definitions:
     - Set explicit search paths to prevent injection (SET search_path = public, pg_temp)
     - Use appropriate security context (SECURITY DEFINER vs INVOKER)
     - Include proper error handling

2. REFERENCE TABLES
   - Create lookup/reference tables in the reference schema
   - These tables should contain static data that rarely changes
   - Include appropriate constraints and descriptions

3. CORE TABLES
   - Define main business entity tables
   - For each table, include:
     - Primary key (using UUIDs)
     - Required columns with appropriate data types
     - Default values where applicable
     - NOT NULL constraints
     - CHECK constraints for data validation
     - Timestamp fields (created_at, updated_at)
     - Description of each column's purpose

For user profiles, follow this pattern:
- Store extended user data in api.profiles, not directly in auth.users
- Link profiles to auth users with a foreign key reference

For all tables, consider:
- Who can create records
- Who can view records
- Who can update records
- Who can delete records

Please generate the complete 001-structure.sql file.
```

### 1.4.4: Relationships Migration

```
Now let's create our third migration file: `002-relationships.sql` which will establish the relationships between our tables and optimize query performance.

This migration will include:

1. RELATIONSHIPS AND FOREIGN KEYS
   - Define all relationships between tables
   - Specify foreign key constraints with appropriate actions:
     - ON DELETE (CASCADE, SET NULL, RESTRICT)
     - ON UPDATE (CASCADE, RESTRICT)
   - Add unique constraints or composite keys where needed
   - Implement check constraints to enforce business rules

2. INDEXES
   - Create indexes for:
     - Foreign keys that will be frequently queried
     - Columns often used in WHERE clauses
     - Columns used for sorting (ORDER BY)
     - Consider composite indexes for multi-column queries
     - Add GIN indexes for JSONB or array columns if needed
   - Remember that each index:
     - Speeds up read operations
     - Slows down write operations
     - Increases storage requirements

3. VIEWS
   - Create views for:
     - Common complex queries
     - Reporting and analytics
     - Joining data across schemas
   - Consider materialized views only for complex analytics that are infrequently updated

For foreign keys, follow this pattern:
- Name constraints clearly (e.g., fk_posts_user_id)
- Consider the impact of cascading deletes
- Index foreign key columns

Please generate the complete 002-relationships.sql file.
```

### 1.4.5: Security Migration

```
Now let's create our final migration file: `003-security.sql` which will implement security, automation, and API functions.

This migration will include:

1. TRIGGERS
   - Create triggers for:
     - Updating timestamp fields (updated_at)
     - Creating related records automatically
     - Enforcing business rules
     - Syncing data between tables
   - Follow these best practices:
     - Use proper schema qualification for function references
     - Create explicit trigger statements (avoid dynamic SQL)
     - Test trigger behavior thoroughly

2. RLS POLICIES
   - Enable Row Level Security on all tables with user data
   - Implement policies for each operation type:
     - FOR SELECT - who can view which records
     - FOR INSERT - who can create records
     - FOR UPDATE - who can modify which records
     - FOR DELETE - who can remove which records
   - Use common policy patterns:
     - Ownership-based access (users see only their data)
     - Role-based access (permissions based on user roles)
     - Relationship-based access (team members can see team data)

3. STORAGE CONFIGURATION
   - Configure storage buckets based on access patterns:
     - public - Openly accessible files
     - protected - Authenticated-only access
     - private - User-specific private files
   - Apply RLS policies to storage buckets to control file access

4. CUSTOM API FUNCTIONS
   - Define database functions for complex operations
   - Ensure each function:
     - Has proper security context
     - Sets explicit search paths
     - Includes error handling
     - Returns appropriate types

For RLS policies, always be aware that:
- Tables with RLS enabled but no policies block all access by default
- policies should be created before or immediately after enabling RLS

For storage policies, always fully qualify column names to avoid ambiguity.

Please generate the complete 003-security.sql file.
```

### 1.4.6: Seed Data

```
Now that we have our database schema defined, let's create a seed.sql file to populate our reference tables with essential data.

For seed data, focus exclusively on:
1. Populating reference tables with required values
2. Including standard lookup data the application needs to function
3. NOT inserting any user data or user-generated content
4. Providing only minimal reference data needed for operation

Examples of appropriate seed data include:
- Status options and types
- Category definitions
- Configuration settings
- Role definitions
- Permission types
- Standard options for dropdown menus
- Other static lookup values

For each reference table:
- Add a comment explaining what data is being inserted
- Use INSERT statements with appropriate values
- Provide consistent IDs for stable references

Please generate a complete seed.sql file we can save as 'supabase/seed.sql'.
```

### 1.4.7: Schema Validation

```
Now that we've created our migration files and seed data, let's validate our schema against the original requirements.

Please review our database design and compare it to the original product requirements:

1. Completeness check:
   - Are all the key entities from the product requirements represented?
   - Have we implemented all necessary relationships?
   - Does the schema support all the main user flows described in the requirements?

2. Pattern implementation:
   - Have we correctly organized our schemas?
   - Are we using proper authentication and profile patterns?
   - Have we correctly implemented subscription tables (if needed)?
   - Do we follow security best practices for RLS policies?

3. Identify any gaps:
   - Are there any requirements not fully supported by this schema?
   - Did we make any design compromises that should be documented?
   - Are there any areas where we diverged from standard patterns, and why?
   - Do we need any additional tables for future requirements?

4. Performance considerations:
   - Will this schema design scale with expected user growth?
   - Have we identified potential performance bottlenecks?
   - Are our indexing strategies appropriate?

Please provide a thoughtful analysis highlighting both strengths of our schema design and areas that might need further refinement.
```

### 1.4.8: Installation Instructions

After generating your migration files and seed data, here's how to install them:

**Using the Supabase Dashboard:**
1. Go to your Supabase project dashboard
2. Navigate to the SQL Editor
3. Create a new query for each migration file
4. Run the migrations in order (000, 001, 002, 003)
5. Run the seed.sql file last
6. If you encounter any errors:
   - Copy the complete error message
   - Paste it back to Claude with a request to fix the issue
   - Apply the corrected SQL script

**Using the Supabase CLI locally:**
1. Save each migration file in the `supabase/migrations/` directory following this naming pattern:
   - `20230101000000_foundation.sql`
   - `20230101000001_structure.sql`
   - `20230101000002_relationships.sql`
   - `20230101000003_security.sql`
2. Save the seed script as `supabase/seed.sql`
3. Run `supabase db reset` to apply all migrations and seed data
4. This gives you a fresh database with schema and test data each time

For your production environment:
- Apply seed data only for essential reference tables
- Remove any test accounts before deployment

After running these, your database will be fully set up with proper security policies, optimizations, and initial data for your application.