# Day 1: Create

[⬅️ Day 1 Overview](README.md)

## 1.4 Database Setup

**Goal**: Define the data structure (schema) required for the web application, creating an `000-initial-migration.sql` file that will fully install a custom Postgres database into your Supabase instance. Also create a `seed.sql` file to populate an initial dataset.

**Process**: Follow this chat pattern with an AI chat tool such as [Claude.ai](https://www.claude.ai). Pay attention to the notes in `[brackets]` and replace the brackets with your own thoughts and ideas.

**Timeframe**: 30-45 minutes

## Table of Contents
- [1.4.1: Initial Schema Analysis](#141-initial-schema-analysis)
- [1.4.2: Core Tables Definition](#142-core-tables-definition)
- [1.4.3: Relationships & Constraints](#143-relationships--constraints)
- [1.4.4: Security Policies](#144-security-policies)
- [1.4.5: Functions & Triggers](#145-functions--triggers)
- [1.4.6: Optimization & Indexing](#146-optimization--indexing)
- [1.4.7: Schema Refinement](#147-optional-schema-refinement)
- [1.4.8: Seed Data](#148-seed-data)
- [1.4.9: Complete Migration Script](#149-complete-migration-script)
- [1.4.10: Schema Validation](#1410-schema-validation)
- [1.4.11: Installation Instructions](#1411-installation-instructions)

### 1.4.1: Initial Schema Analysis

Have this link open and ready to copy/paste in: [supabase-database-patterns.md](../0-learn/supabase-database-patterns.md)

```
You are a Supabase and Postgres and SQL expert tasked with helping an entrepreneur turn his product requirements into helpful Supabase code with proper security. You have a list of personal patterns you always stick to that creates reliably good code. Collect the requirements from the entrepreneur and apply your knowledge and best practice patterns to their domain.

Now that you have your product requirements document, let's design a database schema for your SaaS application. Please paste your completed `product-requirements.md` document from step 1.1 and your `supabase-database-patterns.md` file below:

<product-requirements>
[Paste your PRD here]
</product-requirements>

<supabase-database-patterns>
[Paste the content from the database-patterns.md file linked to above.]
</supabase-database-patterns>

Based on these documents, let's analyze the core entities needed for your database schema. Please help me identify:

1. The schema organization for our application:
   - What custom schemas should we create beyond the reserved Supabase schemas? (api, reference, util, stripe)
   - What types of data should go in each schema?
   - Should we create domain types for common patterns (like email, url)?
   - What enums should we place in the reference schema?

2. Core business objects specific to my application
   - What are the main entities that represent my application's unique value?
   - How do these entities relate to users?
   - What timestamps and audit fields should be included?
   - Should we implement soft deletes with deleted_at timestamps?

3. Profile and authentication extensions
   - How should we extend the default auth.users table?
   - What additional user-related data do we need to store?
   - How should we handle user roles and permissions?

4. Subscription and billing tables for pricing tiers
   - Should we implement the standard Stripe tables outlined in the patterns?
   - What customizations do we need for our specific pricing model?
   - How will we sync subscription data between Stripe and our application? (usually webhooks from Stripe)

5. Usage tracking and analytics requirements
   - What usage metrics do we need to track?
   - How will this data be structured for reporting?
   - Do we need any materialized views for analytics?

For each entity, please identify:
- Key attributes/columns
- Primary identifiers (UUIDs vs serial IDs)
- Basic relationships to other entities
- Access patterns (who needs to read/write this data)

Don't write SQL yet - just create an initial analysis of entities, relationships, and key security/access patterns.
```

### 1.4.2: Core Tables Definition

```
Thank you for the initial analysis. Now let's define the core tables in more detail. For each of the main entities you identified, please provide:

1. Schema and Table name following Supabase naming conventions
2. Complete column list with:
   - Data types 
   - Default values
   - NOT NULL constraints
   - Description of each column's purpose
   - CHECK constraints for data validation
4. Primary key strategy
5. Timestamps and audit fields needed

For each table, also explain:
- Who can create records
- Who can view records
- Who can update records
- Who can delete records

These access patterns will inform our RLS policies later.
```

**Optional**: Advanced feedback questions

```
I'm particularly interested in:

1. Are there any key entities from your product requirements missing?
   [Provide answer]

2. Should we implement soft deletes (using deleted_at) for any tables?
   [Provide answer]

3. What timestamp fields should we include beyond created_at and updated_at?
   [Provide answer]

4. Should we use UUIDs for all primary keys or are there exceptions?
   [Provide answer]
```

### 1.4.3: Relationships & Constraints

```
Now let's define the relationships between our tables.

For each relationship you identified earlier, please specify:

1. The exact foreign key constraints needed
2. Referential integrity actions (ON DELETE, ON UPDATE)
3. Any unique constraints or composite keys
4. Check constraints to enforce data validity

Please structure this as a list of SQL statements we'll need to include in our migration script.
```

**Optional**: Advanced feedback questions

```
Please consider the following questions:

1. How should we handle cascading deletes for user-owned data?
   [Provide answer]

2. Are there any many-to-many relationships requiring junction tables?
   [Provide answer]

3. Do we need any constraints to enforce our business rules?
   [Provide answer]

4. Should any relationships use deferred constraints?
   [Provide answer]
```

### 1.4.4: Security Policies

```
Security is critical for our application. Based on the access patterns we discussed, please define the Row Level Security (RLS) policies needed for each table.

For each table, please specify:
1. Whether we should enable RLS (most tables should have it enabled)
2. FOR SELECT policies - who can view which records
3. FOR INSERT policies - who can create records
4. FOR UPDATE policies - who can modify which records
5. FOR DELETE policies - who can remove which records

Please implement these common policy patterns where appropriate:
- Ownership-based access (users can only see their own data)
- Role-based access (permissions based on user roles)
- Relationship-based access (team members can see team data)

Please structure this as a set of CREATE POLICY statements to include in our migration.
```

**Optional**: Advanced feedback questions

```
Consider the following questions:
1. Do we need any service role bypass mechanisms for background processing?
   [Provide answer]

2. Should some tables have public read access but restricted write access?
   [Provide answer]

3. How should we handle multi-tenant data isolation?
   [Provide answer]

4. Do we need any special policies for admin users?
   [Provide answer]
```

### 1.4.5: Functions & Triggers

```
Now let's define any helper functions and triggers our schema needs.

Please identify and define:

1. Utility functions for common operations:
   - Timestamp management (updating timestamps)
   - User management (creating profiles on signup)
   - Security helper functions (checking permissions)
   - Data validation
   - Complex calculations or aggregations
   
2. Triggers for maintaining data integrity:
   - Updating modified timestamps
   - Syncing data between tables
   - Enforcing business rules
   - Creating related records automatically

3. Functions needed for RLS policies

Please ensure each function follows these security best practices:
- Uses proper schema qualification
- Sets explicit search paths to prevent injection (SET search_path = api, pg_temp)
- Uses appropriate security context (SECURITY DEFINER vs INVOKER)
- Includes proper error handling

Please structure each as a complete SQL function or trigger definition to include in our migration script.
```

**Optional**: Advanced feedback questions

```
Consider:
1. Do we need any functions to handle user signup or deletion?
   [Provide answer]

2. Should we implement triggers for maintaining audit history?
   [Provide answer]

3. Do we need any specialized billing or subscription functions?
   [Provide answer]
```

### 1.4.6: Optimization & Indexing

```
To ensure our database performs well, let's define indexes and optimization strategies.

Please recommend:

1. Indexes for each table, considering:
   - Foreign keys that need indexing
   - Columns frequently used in WHERE clauses
   - Columns used for sorting (ORDER BY)
   - Full-text search requirements
   - Composite indexes for multi-column queries
   - GIN indexes for JSONB or array columns

2. Views or materialized views for:
   - Common complex queries
   - Reporting and analytics
   - Joining data across schemas

3. Performance optimizations for:
   - Large tables (partitioning if needed)
   - Frequently accessed data
   - Complex join operations

Please structure this as a set of SQL statements to include in our migration script.
```

**Optional**: Advanced feedback questions

```
Consider:
1. Which foreign keys will be frequently queried and need indexes?
   [Provide answer]

2. Do we need any specialized indexes like GIN for JSONB columns?
   [Provide answer]

3. Should we implement any materialized views with refresh schedules?
   [Provide answer]
```

### 1.4.7 (_optional_): Schema Refinement

```
I've reviewed your schema design and have some additional thoughts:

1. [Add any concerns about the proposed schema]
2. [Mention any missing entities or attributes]
3. [Note any performance or scaling considerations]
4. [Suggest any simplifications or optimizations]

Based on this feedback, could you refine the schema design before we generate the final migration script?
```

### 1.4.8: Seed Data

```
Now that we have our database schema defined, let's create a seed.sql file to populate only our previously defined reference and lookup tables with essential data.

Based on the tables we've created, please generate a seed.sql file that:

1. Focuses exclusively on populating reference tables with required values
2. Includes standard lookup data that the application needs to function properly
3. Does NOT insert any user data, user-generated content, or business transaction records
4. Provides only the minimal reference data needed for the application to operate correctly

For each reference table, please include:
- A comment explaining what reference data is being inserted
- INSERT statements with appropriate values
- Consistent IDs for stable references (where needed)

Examples of reference data to include:
- Status options and types
- Category definitions
- Configuration settings
- Role definitions
- Permission types
- Standard options for dropdown menus
- Other static lookup values

Please structure this as a complete SQL file we can save as 'supabase/seed.sql'.
```

### 1.4.9: Complete Migration Script

```
Perfect! Based on our discussion and planning, I'd like you to generate the complete SQL migration script for our database.

Please create a comprehensive migration script named '000-initial-migration.sql' that includes:

1. Extension enablement (e.g. pgcrypto)
2. Schema creation
3. Domain types (like email, url) if needed
4. Enum types in the reference schema
5. Utility functions (before they're referenced)
6. Table creation organized by schema
7. Foreign key relationships
8. Security policies for each table
9. Functions and triggers with proper security
10. Indexes and optimizations
11. Views for common query patterns
12. Default values or constants (NOT actual seed data)

Important: Do NOT include seed data in this migration script. The seed data will be in a separate seed.sql file as created in the previous step. This separation allows us to use the Supabase `supabase db reset` command which applies migrations first and then the seed file.

Please ensure the script follows these best practices:
- Creates necessary schemas before using them
- Creates functions before they're referenced by triggers
- Enables RLS on tables with appropriate policies
- Includes proper comments for maintainability
- Follows a logical order of operations

The script should be ready to run directly in the Supabase SQL Editor with no errors.
```

### 1.4.10: Schema Validation

```
Now that we've created our complete database schema, let's take a step back and validate it against our original requirements.

Please review our final database design and compare it back to the original product requirements and database patterns documents:

1. How well does our schema fulfill the core business requirements?
   - Are all the key entities from the product requirements document represented?
   - Have we implemented the necessary relationships between these entities?
   - Does the schema support all the main user flows described in the requirements?

2. Have we properly implemented the Supabase database patterns?
   - Did we follow the schema organization recommendations?
   - Are we using the proper authentication and profile patterns?
   - Have we correctly implemented the suggested pricing and subscription tables?
   - Are we following the security best practices for RLS policies?

3. Identify any potential gaps or misalignments:
   - Are there any requirements that might not be fully supported by this schema?
   - Did we make any design compromises that should be documented?
   - Are there any areas where we diverged from the patterns, and if so, why?
   - Do we need any additional tables or relationships for future requirements?

4. Scalability and performance considerations:
   - Will this schema design scale with our expected user growth?
   - Have we identified potential performance bottlenecks?
   - Are our indexing strategies appropriate for expected query patterns?

Please provide a thoughtful analysis highlighting both the strengths of our schema design and areas that might need further refinement before final implementation.
```

### 1.4.11: Installation Instructions

After generating your complete migration script and seed data file, here's how to install them:

1. Go to your Supabase project dashboard
2. Navigate to the SQL Editor
3. Create a new query and paste the entire migration script
4. Run the script to create your database schema
5. Create another new query and paste the seed data script
6. Run the seed script to populate your tables with initial data
7. If you encounter any errors:
   - Copy the complete error message
   - Paste it back to Claude with a request to fix the issue
   - Claude will help diagnose the problem and provide a corrected SQL script
   - Run the corrected script in Supabase

When using the Supabase CLI locally:
- Save the migration script as `supabase/migrations/000-initial-migration.sql`
- Save the seed script as `supabase/seed.sql`
- The seed file will be automatically applied when you run `supabase db reset`
- This gives you a fresh database with schema and test data each time

For your production environment:
- Apply seed data only for essential reference tables
- Remove any test user accounts before deployment

After running these successfully, your database will be fully set up with proper security policies, optimizations, and initial data for your SaaS application.